##2.3.8-6
升级log4j包版本，解决安全漏洞

##2.3.8-5
拆hive_sql
增加hivesql组件


##2.3.8-2
修改hive.server2.webui.host值


##4.0.2
1.hive升级到2.3.8
2.拆分pkg

##4.0.1
1.hive升级到2.3.8


##4.0.0
1.Hadoop拆分部署
2.hivemetastore库迁移至hive服务
3.配置文件优化
4.配置文件全部提取至Em

## 3.5.4
1.修改hadoop默认http端口，如下：
namenode : 50070 > 60070
datanode : 50075 > 60075
journalnode : 8480 > 18480
nodemanager : 8042 > 18042
resourcenameger : 8088 > 18088
2.启动hadoop-web用户方式访问;
3.关闭yarn:rest-api;

## 3.5.3
presto升级到0.237.1

## 3.5.2
flink 升级至1.8.3;
组件启动脚本jvm 参数优化;
健康检查脚本优化;
hadoop 配置文件支持可添加配置;
增加配置文件capacity-scheduler.xml支持增加队列

## 3.5.1
fix hadoop 3.5.1 hivemetastore conf

## 3.5.0
flink1.8 oom问及解决，hive更新至2.3.6

## 3.4.2
Hadoop 未授权访问漏洞解决

## 3.4.1
Hadoopv2.8.5

## 3.3.7
优化配置文件

## 3.3.6
移除carbon组件，优化日志清理,thriftserver spark-sql-proxy.jar 更新

## 3.3.5
增加presto组件

## 3.3.4
yarn-site.xml yarn.log-aggregation.retain-seconds 支持可配置，默认保存时间由2592000s缩短至604800s

## 3.3.4
hive-site增加动态分区

## 3.3.3
移除组件secondnamenode

## 3.3.2
yarn增加磁盘健康检查，组件增加secondnamenode，提取zookeeper端口

## 3.3.1
修改flink 配置路径，统一归纳到/dtInsight 下

## 3.3.0
spark thriftserver 升级至2.1.3

## 3.2.1
依赖DTApp版本3.9.13

## 3.1.1
新增

## 3.1.0
hivemetastore、thriftserver垃圾回收换成G1，yarn_session下lib包和thriftserver下jars包做更换，主要针对数栈3.9.4,flink3.8.1以上版本

## 3.0.2
spark_history 增加定时清理环境变量参数spark.history.fs.cleaner，Dspark.history.ui.maxApplication

## 3.0.1
spark和flink脚本里去除HADOOP_HOME环境变量，兼容cdh环境

## 3.0.0
yarn_session historyserver版本升级到1.8.1

## 2.0.0
移除了非数栈依赖生态包hbase、ranger、kylin、phonex等
