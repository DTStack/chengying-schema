#2.1.3-6
hivemetastore端口可以配置

#2.1.3-5
优化脚本，适配arm架构
1.优化thriftserver脚本内crontab的逻辑
2.添加spark_base.sh的权限增加逻辑——
  cmd: chmod go+r /etc/profile.d/spark_base.sh


#2.1.3-4
thriftserver上传文件到hdfs是否成功加判断

#2.1.3_3
spark对接cdh不需要上传文件加判断



#2.1.3_2
hive-site.xml中配置纠正
出现警告配置文件问题


# 4.0.4
拆分spark pkg
spark版本是2.1.3
test

## 4.0.3
拆分spark_pkg
spark升级到2.4.7
spark jar包上传到hdfs路径改动
青岛客户生产环境验证测试通过

## 4.0.2
1.新增spark_historyserver日志定时清理配置,默认保存7天

## 4.0.1
1.新增spark /tmp/admin 目录下文件清理定时脚本 delete_file.sh
2.增加定时任务每六小时删除一次文件

## 4.0.0
1.Hadoop拆分部署
2.配置文件优化
3.配置文件全部提取至Em



## 3.5.4
1.修改hadoop默认http端口，如下：
namenode : 50070 > 60070
datanode : 50075 > 60075
journalnode : 8480 > 18480
nodemanager : 8042 > 18042
resourcenameger : 8088 > 18088
2.启动hadoop-web用户方式访问;
3.关闭yarn:rest-api;

## 3.5.3
presto升级到0.237.1

## 3.5.2
flink 升级至1.8.3;
组件启动脚本jvm 参数优化;
健康检查脚本优化;
hadoop 配置文件支持可添加配置;
增加配置文件capacity-scheduler.xml支持增加队列

## 3.5.1
fix hadoop 3.5.1 hivemetastore conf

## 3.5.0
flink1.8 oom问及解决，hive更新至2.3.6

## 3.4.2
Hadoop 未授权访问漏洞解决

## 3.4.1
Hadoopv2.8.5

## 3.3.7
优化配置文件

## 3.3.6
移除carbon组件，优化日志清理,thriftserver spark-sql-proxy.jar 更新

## 3.3.5
增加presto组件

## 3.3.4
yarn-site.xml yarn.log-aggregation.retain-seconds 支持可配置，默认保存时间由2592000s缩短至604800s

## 3.3.4
hive-site增加动态分区

## 3.3.3
移除组件secondnamenode

## 3.3.2
yarn增加磁盘健康检查，组件增加secondnamenode，提取zookeeper端口

## 3.3.1
修改flink 配置路径，统一归纳到/dtInsight 下

## 3.3.0
spark thriftserver 升级至2.1.3

## 3.2.1
依赖DTApp版本3.9.13

## 3.1.1
新增

## 3.1.0
hivemetastore、thriftserver垃圾回收换成G1，yarn_session下lib包和thriftserver下jars包做更换，主要针对数栈3.9.4,flink3.8.1以上版本

## 3.0.2
spark_history 增加定时清理环境变量参数spark.history.fs.cleaner，Dspark.history.ui.maxApplication

## 3.0.1
spark和flink脚本里去除HADOOP_HOME环境变量，兼容cdh环境

## 3.0.0
yarn_session historyserver版本升级到1.8.1

## 2.0.0
移除了非数栈依赖生态包hbase、ranger、kylin、phonex等
